{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through a simple usecase of Neuroprobe and evaluation of the logistic regression baseline. It can be easily adapted to evaluate any foundation model of neural activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected braintreebank data at: C:\\Users\\User\\Documents\\UNI\\BRAIN\\braintree\n",
      "Sampling rate: 2048 Hz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# NOTE: Change this to your own path, or define an environment variable elsewhere\n",
    "os.environ['ROOT_DIR_BRAINTREEBANK'] = r'C:\\Users\\User\\Documents\\UNI\\BRAIN\\braintree' \n",
    "\n",
    "import torch\n",
    "import neuroprobe.config as neuroprobe_config\n",
    "\n",
    "# Make sure the config ROOT_DIR is set correctly\n",
    "print(\"Expected braintreebank data at:\", neuroprobe_config.ROOT_DIR)\n",
    "print(\"Sampling rate:\", neuroprobe_config.SAMPLING_RATE, \"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The BrainTreebankSubject Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded subject 3\n",
      "Electrode labels (first 10): ['F2Ia1', 'F2Ia2', 'F2Ia3', 'F2Ia4', 'F2Ia5', 'F2Ia6', 'F2Ia7', 'F2Ia8', 'F2Ia9', 'F2Ia10']\n",
      "\n",
      "Electrode coordinates (MNI space) of the first 10 electrodes:\n",
      "tensor([[ 52.0551, -49.1958,  -0.2968],\n",
      "        [ 52.4313, -47.6345,  -2.4238],\n",
      "        [ 54.8303, -43.2729,  -5.6083],\n",
      "        [ 55.2545, -38.4559,  -7.9876],\n",
      "        [ 57.9486, -35.4795,  -9.0304],\n",
      "        [ 59.5240, -33.7188,  -9.7763],\n",
      "        [ 61.0274, -31.4587, -10.8302],\n",
      "        [ 62.1906, -28.7069, -12.2043],\n",
      "        [ 83.5639, -10.3173, -16.6571],\n",
      "        [ 82.7500,  -7.8472, -16.6011]])\n"
     ]
    }
   ],
   "source": [
    "from neuroprobe import BrainTreebankSubject\n",
    "\n",
    "subject_id = 3\n",
    "\n",
    "coordinates_type = \"cortical\" # \"cortical\", \"mni\", \"lpi\". NOTE: MNI are not yet available for the Braintreebank dataset.\n",
    "# cortical = standardized brain atlas cortical projection of the coordinates in Freesurfer space\n",
    "# mni = MNI coordinates\n",
    "# lpi = LPI coordinates (left, posterior, inferior) in the subject's coordinate system\n",
    "\n",
    "# use cache=True to load this trial's neural data into RAM, if you have enough memory!\n",
    "# It will make the loading process faster.\n",
    "subject = BrainTreebankSubject(subject_id, allow_corrupted=False, cache=True, dtype=torch.float32, coordinates_type=coordinates_type)\n",
    "print(\"Loaded subject\", subject_id)\n",
    "print(\"Electrode labels (first 10):\", subject.electrode_labels[:10]) # list of electrode labels\n",
    "\n",
    "print(\"\\nElectrode coordinates (MNI space) of the first 10 electrodes:\")\n",
    "print(subject.get_electrode_coordinates()[:10]) # L, P, I coordinates of the electrodes\n",
    "\n",
    "# Optionally, subset the electrodes to a specific set of electrodes. NOTE: you should not do this if you are using the neuroprobe as a standardized benchmark.\n",
    "# subject.set_electrode_subset(['F3aOFa2', 'F3aOFa3', 'F3aOFa4', 'F3aOFa7']) # if you change this line when using cache=True, you need to clear the cache after: subject.clear_neural_data_cache()\n",
    "# print(\"Electrode labels after subsetting:\", subject.electrode_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the electrode data from a specific trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All neural data shape:\n",
      "torch.Size([112, 14017056])\n",
      "\n",
      "First 50 samples of the first electrode (data is in microvolts):\n",
      "tensor([60.3463, 61.4097, 56.6245, 57.6879, 59.5488, 59.8146, 58.4854, 55.8270,\n",
      "        57.1562, 59.2829, 59.5488, 57.6879, 58.2195, 60.6121, 59.2829, 61.4097,\n",
      "        63.5364, 61.6755, 61.1438, 61.6755, 61.4097, 60.3463, 60.0804, 59.2829,\n",
      "        61.1438, 60.0804, 61.1438, 63.2706, 63.8022, 61.4097, 60.0804, 63.2706,\n",
      "        61.9413, 62.2072, 64.0681, 64.8656, 63.5364, 63.2706, 66.1948, 66.1948,\n",
      "        66.4607, 66.7265, 66.1948, 65.9290, 68.5874, 69.1191, 66.1948, 70.1825,\n",
      "        69.6508, 68.3216])\n"
     ]
    }
   ],
   "source": [
    "trial_id = 0\n",
    "\n",
    "subject.load_neural_data(trial_id)\n",
    "window_from = None # This is the index into the neural data array from where to start loading the data.\n",
    "window_to = None # if None, the whole trial will be loaded\n",
    "\n",
    "all_neural_data = subject.get_all_electrode_data(trial_id, window_from=window_from, window_to=window_to)\n",
    "\n",
    "print(\"All neural data shape:\")\n",
    "print(all_neural_data.shape) # (n_electrodes, n_samples). To get the data for a specific electrode, use subject.get_electrode_data(trial_id, electrode_label)\n",
    "\n",
    "print(\"\\nFirst 50 samples of the first electrode (data is in microvolts):\")\n",
    "print(all_neural_data[0, :50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The BrainTreebankSubjectTrialBenchmarkDataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In the dataset below, there will be fewer electrodes than in the full subject data. This is because the Neuroprobe benchmark only uses a subset of the electrodes for standardized and quick benchmarking. The electrode labels below are subset to the `neuroprobe_config.NEUROPROBE_LITE_ELECTRODES` list.\n",
    "\n",
    "Accordingly, when using the `BrainTreebankSubjectTrialBenchmarkDataset` with `lite=True` (which is the default Neuroprobe benchmark option), make sure that you use the `dataset.electrode_labels` and `dataset.electrode_coordinates` properties, which give the electrode labels and the electrode coordinates in MNI space, respectively, in the exact order that the `dataset` will output the data tensors in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "eval_name must be one of ['enhanced_pitch', 'rms', 'mean_pixel_brightness', 'max_global_magnitude', 'max_vector_magnitude', 'delta_rms', 'gpt2_surprisal', 'word_length', 'pitch', 'volume', 'frame_brightness', 'global_flow', 'local_flow', 'delta_volume', 'gpt2_surprisal', 'word_length', 'enhanced_pitch', 'enhanced_volume', 'delta_enhanced_pitch', 'delta_enhanced_volume', 'raw_pitch', 'raw_volume', 'delta_raw_pitch', 'delta_raw_volume', 'onset', 'speech', 'face_num', 'word_gap', 'word_index', 'bin_head', 'pos', 'word_head_pos', 'word_part_speech'], not scene_onset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m start_neural_data_before_word_onset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# the number of samples to start the neural data before each word onset\u001b[39;00m\n\u001b[0;32m     13\u001b[0m end_neural_data_after_word_onset \u001b[38;5;241m=\u001b[39m neuroprobe_config\u001b[38;5;241m.\u001b[39mSAMPLING_RATE \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# the number of samples to end the neural data after each word onset -- here we use 1 second\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mBrainTreebankSubjectTrialBenchmarkDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mstart_neural_data_before_word_onset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_neural_data_before_word_onset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_neural_data_after_word_onset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_neural_data_after_word_onset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# the default is Neuroprobe Lite for standardized and quick benchmarking. Feel free to set lite=false if trying to access the Full dataset.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# P.S. Allow partial cache -- whether to allow partial caching of the neural data, if only part of it is needed for this particular dataset. Better set to False when doing multiple evals back to back, but better set to True when doing a single eval.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m data_electrode_labels \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39melectrode_labels \u001b[38;5;66;03m# NOTE: this is different from the subject.electrode_labels! Neuroprobe uses a special subset of electrodes in this exact order.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\gait_fixed\\lib\\site-packages\\neuroprobe\\datasets.py:72\u001b[0m, in \u001b[0;36mBrainTreebankSubjectTrialBenchmarkDataset.__init__\u001b[1;34m(self, subject, trial_id, dtype, eval_name, output_indices, binary_tasks, start_neural_data_before_word_onset, end_neural_data_after_word_onset, lite, nano, random_seed, output_dict, max_samples, always_cache_full_subject)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Set up a local random state with the provided seed\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(random_seed)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m eval_name \u001b[38;5;129;01min\u001b[39;00m all_tasks, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_name must be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_tasks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject \u001b[38;5;241m=\u001b[39m subject\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject_id \u001b[38;5;241m=\u001b[39m subject\u001b[38;5;241m.\u001b[39msubject_id\n",
      "\u001b[1;31mAssertionError\u001b[0m: eval_name must be one of ['enhanced_pitch', 'rms', 'mean_pixel_brightness', 'max_global_magnitude', 'max_vector_magnitude', 'delta_rms', 'gpt2_surprisal', 'word_length', 'pitch', 'volume', 'frame_brightness', 'global_flow', 'local_flow', 'delta_volume', 'gpt2_surprisal', 'word_length', 'enhanced_pitch', 'enhanced_volume', 'delta_enhanced_pitch', 'delta_enhanced_volume', 'raw_pitch', 'raw_volume', 'delta_raw_pitch', 'delta_raw_volume', 'onset', 'speech', 'face_num', 'word_gap', 'word_index', 'bin_head', 'pos', 'word_head_pos', 'word_part_speech'], not scene_onset"
     ]
    }
   ],
   "source": [
    "from neuroprobe import BrainTreebankSubjectTrialBenchmarkDataset\n",
    "\n",
    "# Options for eval_name (from the Neuroprobe paper): neuroprobe_config.EVAL_NAMES\n",
    "#   frame_brightness, global_flow, local_flow, face_num, volume, pitch, delta_volume, \n",
    "#   speech, onset, scene_onset, gpt2_surprisal, word_length, word_gap, word_index, word_head_pos, word_part_speech, speaker\n",
    "eval_name = \"scene_onset\"  # Try \"scene_onset\" to detect scene changes in the movie\n",
    "\n",
    "# if True, the dataset will output the indices of the samples in the neural data in a tuple: (index_from, index_to); \n",
    "# if False, the dataset will output the neural data directly\n",
    "output_indices = False\n",
    "\n",
    "start_neural_data_before_word_onset = 0 # the number of samples to start the neural data before each word onset\n",
    "end_neural_data_after_word_onset = neuroprobe_config.SAMPLING_RATE * 1 # the number of samples to end the neural data after each word onset -- here we use 1 second\n",
    "\n",
    "dataset = BrainTreebankSubjectTrialBenchmarkDataset(subject, trial_id, dtype=torch.float32, eval_name=eval_name, output_indices=output_indices, \n",
    "                                                    start_neural_data_before_word_onset=start_neural_data_before_word_onset, end_neural_data_after_word_onset=end_neural_data_after_word_onset,\n",
    "                                                    lite=True) # the default is Neuroprobe Lite for standardized and quick benchmarking. Feel free to set lite=false if trying to access the Full dataset.\n",
    "# P.S. Allow partial cache -- whether to allow partial caching of the neural data, if only part of it is needed for this particular dataset. Better set to False when doing multiple evals back to back, but better set to True when doing a single eval.\n",
    "\n",
    "data_electrode_labels = dataset.electrode_labels # NOTE: this is different from the subject.electrode_labels! Neuroprobe uses a special subset of electrodes in this exact order.\n",
    "data_electrode_coordinates = dataset.electrode_coordinates \n",
    "\n",
    "print(\"Items in the dataset:\", len(dataset), \"\\n\")\n",
    "print(f\"The first item: (shape = {dataset[0][0].shape})\", dataset[0][0], f\"label = {dataset[0][1]}\", sep=\"\\n\")\n",
    "print(\"\")\n",
    "print(f\"Electrode labels in the data above in the following order ({len(data_electrode_labels)} electrodes):\", data_electrode_labels)\n",
    "print(f\"Electrode coordinates in the data above in the following order ({len(data_electrode_coordinates)} electrodes):\", data_electrode_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': tensor([[-34.0279, -33.4962, -32.4328,  ...,  21.0016,  22.0649,  22.0649],\n",
      "        [ 10.6337,   9.8362,   9.3045,  ..., -34.0279, -33.4962, -32.6987],\n",
      "        [ 59.2829,  59.2829,  63.0047,  ..., -26.0526, -25.2551, -23.6600],\n",
      "        ...,\n",
      "        [-42.5348, -42.5348, -43.3324,  ...,  -4.2535,  -5.3169,  -4.5193],\n",
      "        [-16.2164, -14.8872, -14.8872,  ..., -18.3431, -16.2164, -15.9506],\n",
      "        [ -0.7975,   0.2658,  -3.1901,  ...,   1.3292,   4.5193,   4.5193]]), 'label': 1, 'electrode_labels': ['T1cIe5', 'T1cIe6', 'T1cIe7', 'T1cIe8', 'T1cIe9', 'T1cIe10', 'T1cIe11', 'T1cIe12', 'T1b1', 'T1b2', 'T1b3', 'T1b4', 'T1b5', 'T1b6', 'T1aIc3', 'T1aIc4', 'T1aIc5', 'T1aIc6', 'O1aIb9', 'O1aIb10', 'O1aIb11', 'O1aIb12', 'O1aIb13', 'O1aIb14', 'O1aIb15', 'O1aIb16', 'F3d1', 'F3d2', 'F3d3', 'F3d4', 'F3d5', 'F3d6', 'F3d7', 'F3d8', 'F3d9', 'F3d10', 'F3aOF1', 'F3aOF2', 'F3aOF3', 'F3aOF4', 'F3aOF5', 'F3aOF6', 'F3aOF7', 'F3aOF8', 'F3c1', 'F3c2', 'F3c3', 'F3c4', 'F3c5', 'F3c6', 'F2Ia1', 'F2Ia2', 'F2Ia3', 'F2Ia4', 'F2Ia5', 'F2Ia6', 'F2Ia7', 'F2Ia8', 'F2Ia9', 'F2Ia10', 'F2Ia11', 'F2Ia12', 'F2Ia13', 'F2Ia14', 'P2a1', 'P2a2', 'P2a3', 'P2a4', 'P2a5', 'P2a6', 'P2a7', 'P2a8', 'P2a9', 'O1bId8', 'O1bId9', 'O1bId10', 'O1bId11', 'O1bId12', 'O1bId13', 'O1bId14', 'O1bId15', 'O1bId16', 'F3b7', 'F3b8', 'O1bId1', 'O1bId2', 'O1bId3', 'O1bId4', 'O1bId5', 'F3b1', 'F3b2', 'F3b3', 'F3b4', 'P2b3', 'P2b4', 'P2b5', 'P2b6', 'P2b7', 'P2b8', 'P2b9', 'P2b10', 'P2b11', 'P2b12', 'P2b13', 'P2b14', 'P2b15', 'P2b16', 'T1cIe1', 'T1cIe2'], 'electrode_coordinates': tensor([[  7.4584, -23.1151, -24.4406],\n",
      "        [  7.0404, -23.5734, -25.2141],\n",
      "        [  7.1434, -24.5782, -26.0889],\n",
      "        [ -6.4634, -20.3280, -33.7628],\n",
      "        [ -9.3660, -30.1353, -40.7724],\n",
      "        [ -9.8560, -28.2845, -40.3674],\n",
      "        [ -9.7807, -27.5583, -40.1042],\n",
      "        [ -9.6552, -25.1724, -39.0246],\n",
      "        [ 13.2008, -34.7912, -29.7471],\n",
      "        [  8.2385, -34.1993, -34.2417],\n",
      "        [  4.7607, -35.2475, -37.3761],\n",
      "        [  4.5473, -33.3468, -36.5238],\n",
      "        [  3.1460, -32.5822, -36.9749],\n",
      "        [  2.2693, -31.5031, -36.8797],\n",
      "        [ 20.0962, -43.4916, -28.5686],\n",
      "        [ 18.8054, -42.0627, -29.1324],\n",
      "        [ 15.8635, -43.5542, -33.0622],\n",
      "        [ 15.8987, -43.0177, -32.7739],\n",
      "        [-11.8625, -13.1464, -31.0688],\n",
      "        [-15.2893, -10.9720, -31.9993],\n",
      "        [-35.8532, -18.2679, -38.8795],\n",
      "        [-43.8980, -10.7776, -36.0216],\n",
      "        [-45.2589, -10.8667, -35.4456],\n",
      "        [-53.0050, -12.4383, -32.2775],\n",
      "        [-55.9356, -10.0113, -30.6584],\n",
      "        [-57.0849, -10.7127, -30.3023],\n",
      "        [ 28.4657, -12.1890, -16.5807],\n",
      "        [ 27.5092, -12.0673, -16.5863],\n",
      "        [ 29.6512, -11.1333, -18.3607],\n",
      "        [ 27.4170, -10.3615, -19.3621],\n",
      "        [ 25.8363,  -9.0426, -22.7042],\n",
      "        [ 26.0947,  -8.6070, -24.4207],\n",
      "        [ 24.9599,  -8.1073, -25.8629],\n",
      "        [ 27.1987,  -7.3305, -28.9594],\n",
      "        [ 25.3319,  -4.3118, -34.6363],\n",
      "        [ 28.4975,  -4.3947, -33.6986],\n",
      "        [ 74.9401, -47.7333,   4.8198],\n",
      "        [ 71.9903, -46.4699,   1.1377],\n",
      "        [ 59.4927, -38.6994,  -7.6550],\n",
      "        [ 75.6259, -43.3032,  -2.9802],\n",
      "        [ 74.2660, -42.0175,  -4.7595],\n",
      "        [ 66.6962, -37.7490,  -8.3772],\n",
      "        [ 68.3334, -37.3085,  -8.7736],\n",
      "        [ 72.0240, -37.9672,  -8.5598],\n",
      "        [ 46.9777, -17.9036, -14.6722],\n",
      "        [ 48.2400, -17.6538, -15.0995],\n",
      "        [ 50.5528, -15.7214, -17.3544],\n",
      "        [ 51.6526, -14.3314, -19.1120],\n",
      "        [ 56.1653, -14.0882, -20.4235],\n",
      "        [ 59.9121, -13.8328, -21.2362],\n",
      "        [ 52.0551, -49.1958,  -0.2968],\n",
      "        [ 52.4313, -47.6345,  -2.4238],\n",
      "        [ 54.8303, -43.2729,  -5.6083],\n",
      "        [ 55.2545, -38.4559,  -7.9876],\n",
      "        [ 57.9486, -35.4795,  -9.0304],\n",
      "        [ 59.5240, -33.7188,  -9.7763],\n",
      "        [ 61.0274, -31.4587, -10.8302],\n",
      "        [ 62.1906, -28.7069, -12.2043],\n",
      "        [ 83.5639, -10.3173, -16.6571],\n",
      "        [ 82.7500,  -7.8472, -16.6011],\n",
      "        [ 92.0290,   6.9156,  -0.4063],\n",
      "        [ 90.4003,   4.9078,  -3.7872],\n",
      "        [ 89.1333,   4.2577,  -5.6243],\n",
      "        [ 95.9115,  11.5498,   8.9235],\n",
      "        [  9.9786,  -7.0739, -21.4446],\n",
      "        [ 10.5524,  -6.5771, -23.0358],\n",
      "        [ 11.9028,  -5.6699, -26.7675],\n",
      "        [ 11.2262,  -3.7707, -31.4203],\n",
      "        [  9.6935,  -2.8079, -32.4195],\n",
      "        [  4.9711,   1.2905, -35.7994],\n",
      "        [  6.3079,   2.8326, -37.6886],\n",
      "        [  7.0915,   4.9652, -39.1928],\n",
      "        [  9.5407,   5.3458, -39.6943],\n",
      "        [ 16.4535, -29.5672, -22.4124],\n",
      "        [-67.6108, -13.3213, -26.5182],\n",
      "        [-67.9246, -12.7021, -26.2648],\n",
      "        [-68.7690,  -9.6749, -25.3261],\n",
      "        [-81.5909, -14.2223, -19.8383],\n",
      "        [-72.1987,  -2.5059, -22.5226],\n",
      "        [-81.3931,  -5.7490, -18.5014],\n",
      "        [-82.7856,  -5.1844, -17.5443],\n",
      "        [-84.5268,  -2.8146, -15.8300],\n",
      "        [ 77.4331, -20.0990, -18.8129],\n",
      "        [ 74.5586, -19.2639, -19.4404],\n",
      "        [ 33.2269, -48.2845, -16.0869],\n",
      "        [ 32.9578, -47.7421, -16.3175],\n",
      "        [ 29.2342, -42.7611, -18.7457],\n",
      "        [ 25.9474, -39.8861, -20.5235],\n",
      "        [ 24.3078, -36.7982, -20.5005],\n",
      "        [ 64.2267, -29.3081, -12.3410],\n",
      "        [ 65.4463, -28.7108, -12.9059],\n",
      "        [ 67.7460, -27.4845, -14.1182],\n",
      "        [ 70.2153, -27.5438, -14.6712],\n",
      "        [ -8.7524,  -3.0255, -25.1408],\n",
      "        [ -8.8015,  -2.0916, -26.0965],\n",
      "        [ -8.7252,  -1.1481, -27.2164],\n",
      "        [ -9.0143,  -0.2693, -28.3154],\n",
      "        [ -8.6641,   0.4225, -29.2554],\n",
      "        [-15.8351,   5.4119, -34.0569],\n",
      "        [-15.8488,   5.8281, -34.3909],\n",
      "        [-15.8460,   7.1074, -35.3668],\n",
      "        [-17.2948,   9.3653, -36.8024],\n",
      "        [-16.6278,  10.9171, -37.6609],\n",
      "        [-15.5010,  11.1927, -37.8750],\n",
      "        [-15.7984,  12.9784, -38.5975],\n",
      "        [-14.6268,  13.2405, -38.7890],\n",
      "        [-14.7827,  15.5672, -39.3794],\n",
      "        [ 14.6401, -20.6693, -18.4343],\n",
      "        [ 13.9929, -20.6318, -18.7102]]), 'metadata': {'dataset_identifier': 'braintreebank', 'subject_id': 3, 'trial_id': 0, 'sampling_rate': 2048}}\n"
     ]
    }
   ],
   "source": [
    "# Optionally, you can request the output_dict=True to get the data as a dictionary with a bunch of metadata.\n",
    "dataset.output_dict = True\n",
    "print(dataset[0])\n",
    "\n",
    "dataset.output_dict = False # set it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((848237, 850285), 1)\n"
     ]
    }
   ],
   "source": [
    "# Also, you can request only the indices into the neural data array, instead of the actual data.\n",
    "# NOTE: These are the indices into the data as in the raw h5 files in the braintreebank dataset.\n",
    "\n",
    "dataset.output_indices = True\n",
    "print(dataset[0]) # Data format: (index_from, index_to), label\n",
    "\n",
    "dataset.output_indices = False # set it back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Splits\n",
    "\n",
    "In this example, we generate train/test splits for the WithinSession evaluation.\n",
    "\n",
    "All options: generate_splits_within_session, generate_splits_cross_session, generate_splits_cross_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(folds) = k_folds = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_dataset': <torch.utils.data.dataset.Subset at 0x205dc62fe80>,\n",
       "  'test_dataset': <torch.utils.data.dataset.Subset at 0x205dc62e9b0>},\n",
       " {'train_dataset': <torch.utils.data.dataset.Subset at 0x205dc62eb30>,\n",
       "  'test_dataset': <torch.utils.data.dataset.Subset at 0x205dc62fc40>}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neuroprobe.train_test_splits as neuroprobe_train_test_splits\n",
    "\n",
    "folds = neuroprobe_train_test_splits.generate_splits_within_session(subject, trial_id, eval_name, dtype=torch.float32, \n",
    "                                                                                # Put the dataset parameters here\n",
    "                                                                                output_indices=output_indices, start_neural_data_before_word_onset=start_neural_data_before_word_onset, end_neural_data_after_word_onset=end_neural_data_after_word_onset,\n",
    "                                                                                lite=True)\n",
    "print(\"len(folds) = k_folds =\", len(folds))\n",
    "folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Linear Regression on SS_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 2\n",
      "\t Train accuracy: 1.000 | Test accuracy: 0.618\n",
      "Fold 2 of 2\n",
      "\t Train accuracy: 1.000 | Test accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "for fold_idx, fold in enumerate(folds):\n",
    "    print(f\"Fold {fold_idx+1} of {len(folds)}\")\n",
    "    train_dataset = fold[\"train_dataset\"]\n",
    "    test_dataset = fold[\"test_dataset\"]\n",
    "\n",
    "    # Convert PyTorch dataset to numpy arrays for scikit-learn\n",
    "    X_train = np.array([item[0].flatten() for item in train_dataset])\n",
    "    y_train = np.array([item[1] for item in train_dataset])\n",
    "    X_test = np.array([item[0].flatten() for item in test_dataset])\n",
    "    y_test = np.array([item[1] for item in test_dataset])\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train logistic regression\n",
    "    clf = LogisticRegression(random_state=42, max_iter=1000, tol=1e-3)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(f\"\\t Train accuracy: {train_score:.3f} | Test accuracy: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.494884485922654"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(X_train.size * 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait_fixed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
